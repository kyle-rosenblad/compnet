---
title: "The 'compnet' workflow"
author: "[Kyle Rosenblad](https://www.kylerosenblad.org/)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{compnet_workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(compnet)
```

# Introduction

The goal of a 'compnet' analysis is to quantify the effect of competitive niche differentiation on community assembly for a group of species. Competitive niche differentiation is a process whereby functional dissimilarity between species promotes co-occurrence through decreased overlap in resource use. Our input data will include a species-by-site presence-absence matrix, as well as one or more species-level variables (e.g., plant rooting depth) and/or variables that only pertain to pairs of species (e.g., phylogenetic distance).

Before using 'compnet', we'll translate our conceptual goal into a quantitative "estimand" (i.e., something we're aiming to estimate with our model). Our estimand will be the effect of functional dissimilarity between two species (as quantified via one or more traits; see above) on the probability of co-occurrence. We will define the probability of co-occurrence for a species pair as the probability that both species in the pair co-occur at a given site, given that at least one of them is present.

To estimate the effect of functional dissimilarity on co-occurrence probabilities, we will use a regression model, in which the units of analysis are species pairs. The response variable is the ratio of sites containing both species to sites containing at least one of the two species. For example, if 3 sites have Species A only, 2 sites have Species B only, and 5 sites have both, the value of our response variable would be 5/10=0.5 for this species pair. The predictor(s) can encompass traits that we think might influence competitive niche differentiation (e.g., plant species' rooting depth), or pair-level variables that could serve as a proxy for functional dissimilarity (e.g., phylogenetic distance). We can include as many predictors as we want. We'll take advantage of this fact later, when we adjust for a suspected confounding variable.

Using species pairs as units of analysis can cause problems for typical regression models, and 'compnet' has tools for dealing with these problems. When we build a regression model (e.g., a linear regression, GLM, GLMM, etc.), we usually assume that the errors are independently distributed. This assumption will likely be violated if we model species pairs in a network without taking special steps. One problem is that all pairs that include a given species might share features in common. All 'compnet' models include components designed to account for this kind of pattern. Additionally, there can be higher-order patterns of non-independence among species pairs--e.g., "the enemy of my enemy is my friend". 'compnet' also has optional model features for dealing with these higher-order patterns, which we will demonstrate below. Further technical details are discussed in LINK PREPRINT.

Let's get started!

# Data prep

```{r}
set.seed(287) # Ensure reproducibility

# Load an example presence-absence matrix:
data("ex_presabs")

# View the first few rows and columns.
# Rows are sites, and columns are species.
# rownames and colnames are specified accordingly.
ex_presabs[1:3, 1:3]
```

```{r}

# Load example species-level trait data:
data("ex_traits")

# View the first few species.
# Rows are species, and columns are traits.
# rownames and colnames are specified accordingly.
ex_traits[1:3,]

```

# Model with one species trait (5-10 min.)

In the example data set, "ndtrait" is a trait that we think might drive competitive niche differentiation (e.g., plant rooting depth), and "domtrait" is a trait that we think might influence competitive ability (e.g., plant height). First we'll build a model with just "ndtrait", as competitive niche differentiation is the process we're interested in.

If "ndtrait" is driving competitive niche differentiation, then we expect species pairs who differ strongly in this trait to co-occur most often. We'll model the effect of "ndtrait" on co-occurrence probability using a "distance interaction" term. In other words, for each species pair, our model will use species A's value of "ndtrait", species B's value, and the absolute value of the difference between these two values. This last term directly captures the effect we're interested in, which is called "heterophily" in the social sciences (i.e., things that are different being attracted to each other). Social scientists often model heterophily using a multiplicative interaction term instead of a distance term, but I generally find this approach less optimal for studying competitive niche differentiation. (Nonetheless, buildcompnet() also allows for multiplicative interactions if we specify 'spvars_multi_int'.)

Stan, the statistical software under the hood, uses an algorithm called NUTS to estimate our results for us. If we don't let NUTS run for enough iterations, we can't trust our results. Stan will tell us if we didn't let our model run long enough, and it will provide web links to help resources.

Before we try to build a good model, let's deliberately tell NUTS to do a very small number of iterations so we can see what those warnings look like:

```{r}
shortrun <- buildcompnet(presabs=ex_presabs,
                  spvars_dist_int=ex_traits[c("ndtrait")],
                  warmup=100,
                  iter=200)
```

Now let's build our first distance interaction model. We'll call it 'nd_0_mod' because we're using "ndtrait" as a predictor, and we're using the default 'rank' value of 0. (We'll discuss the importance of this rank = 0 decision shortly.) Sometimes, it takes a few tries at gradually adjusting 'warmup' and 'iter' until you're getting sufficient samples to avoid warnings. I've already done that trial and error for this example data set, so I'll set 'warmup' and 'iter' at the sweet spot. (The default settings will produce a longer run, but we don't need that here.)

```{r}
nd_0_mod <- buildcompnet(presabs=ex_presabs,
        spvars_dist_int=ex_traits[c("ndtrait")],
        warmup=400,
        iter=1200)
```

Before we try to interpret any results, let's see if this model provides a reasonable fit to the data. One of our main concerns with network data is the multiple forms of non-independence that can arise among observations, as discussed in the Introduction. Let's use the 'gofstats' function to check how well our model accounts for these types of non-independence in the example data set:

```{r}
nd_0_mod_gofstats <- gofstats(nd_0_mod)
nd_0_mod_gofstats
```

The first 'p-value', 'p.sd.rowmeans', tells us about patterns driven by the fact that all species pairs including a given species share features in common. Our 'p.sd.rowmeans' is low, which means when we simulate data from the model we've built ('gofstats' did this in the background), most of the simulated data have at least as much of this kind of non-independence as the real data. That's good; it means our model is accounting for this form of non-independence among species pairs. Anything that's not super-high (around maybe 0.9ish or more) is fine.

The second value, 'p.cycle.dep', tells us about higher-order multi-species patterns. These can be abstract and challenging to conceptualize. A good example is the saying, "the enemy of my enemy is my friend". Our 'p.cycle.dep' looks fine. It's telling us that when we simulate data from our model, around two thirds of the simulated data sets have less high-order non-independence than the real data. We wouldn't usually worry about a 'p.cycle.dep' value like this, but for the sake of illustration, let's try increasing 'rank', which can be helpful when 'p.cycle.dep' is problematically high.

Also, notice I had to adjust 'adapt_delta' to make sampling to run smoothly for this model. Adjusting 'adapt_delta' can help when Stan gives warnings about "divergent transitions". To see the warnings, you could try running this model with 'adapt_delta' at an inadvisably low level like 0.7.

```{r}
nd_1_mod <- buildcompnet(presabs=ex_presabs,
        spvars_dist_int=ex_traits[c("ndtrait")],
        rank=1,
        warmup=300,
        iter=1000,
        adapt_delta=0.9)
nd_1_mod_gofstats <- gofstats(nd_1_mod)
nd_1_mod_gofstats

```

Unsurprisingly, our gofstats look fine.

Before we move forward with this model, I recommend using the 'DHARMa' package to run some additional checks for model fit problems. 'DHARMa' doesn't automatically install with 'compnet'. If you have your own model diagnostic workflow, you don't need to use it.

We'll use 'DHARMa' to check for overdispersion, quantile deviations, uniformity, and zero inflation. You can read more about these issues and their accompanying tests in the 'DHARMa' [vignette](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html). In general, we should be wary of tiny p-values, warning messages, and visual patterns that deviate strongly from the expected patterns shown in DHARMa's output graphs. However, when you have a very large data set, you can get tiny p-values even when the deviations from the expected patterns are trivial. The diagnostic plots are key in these cases.

```{r}
library(DHARMa)
nd_1_mod_ppred <- postpredsamp(nd_1_mod)
fpr <- apply(nd_1_mod_ppred, 1, mean)
nd_1_mod_dharma <- createDHARMa(simulatedResponse = nd_1_mod_ppred,
                                observedResponse = nd_1_mod$d$both,
                                fittedPredictedResponse = fpr,
                                integerResponse = TRUE)
testDispersion(nd_1_mod_dharma)
testQuantiles(nd_1_mod_dharma)
testUniformity(nd_1_mod_dharma)
testZeroInflation(nd_1_mod_dharma)
```

This all looks fine. Going forward, to keep this vignette brief, we'll suppress the plots that accompany DHARMa tests, but I always recommend checking the plots when you're analyzing your own data.

Now let's explore our results. First we'll peek at the coefficients for our predictors of interest:

```{r}
summarize_compnet(nd_1_mod)
```

Let's see those as violin plots:

```{r}
fixedeff_violins(nd_1_mod)
```

Now we'll make a scatterplot, in which each point is a species pair. The x axis will represent the trait value for "Species A" (A vs B is arbitrary), and the y axis will represent co-occurrence probability. We'll include curves for the mean expectation with 95% credible intervals. There will be multiple curves, each conditioned on a different value of the focal trait for "Species B". By default, the scatter_interaction() function will generate the plot by conditioning on the mean values of all other predictor variables pertaining to other traits. (In this example model, "ndtrait" is the only trait.)

```{r fig.height=6, fig.width=6}
scatter_interaction(nd_1_mod, xvar="ndtrait", xlabel="ND Trait")
```

Cool! When Species B has a low value of "ndtrait", the co-occurrence probability increases with Species A's "ndtrait" value. In other words, if you have a low value of "ndtrait", you'll be more likely to co-occur with other species that have high values. This pattern is consistent with competitive niche differentiation. Similarly, when Species B's "ndtrait" value is high, co-occurrence probability decreases with Species A's value. Additionally, when Species B has an intermediate value of "ndtrait", co-occurrence probability is higher when Species A's value is at either extreme, with a dip in the middle. (This is the pattern that multiplicative interaction models--as opposed to distance interaction models--struggle to represent.) Overall, this plot exemplifies the results we expect for a metacommunity shaped by competitive niche differentiation.

# Model with two traits (8-15 min.)

When might we want to use multiple traits in the same model? For one, we might want to use this strategy to deal with a suspected confounder or "lurking variable".

So far, we've just been using "ndtrait", the trait that we think drives competitive niche differentiation. In general, competitive niche differentiation is expected to produce heterophily, a pattern whereby species with different trait values co-occur most often. However, we've got data for another trait called "domtrait", which we think might influence competitive ability. In general, competitive hierarchies produce homophily--i.e., species co-occur most frequently with other species of similar competitive ability. If there's an association between "ndtrait" and "domtrait", then the homophily caused by "domtrait" might be masking the heterophily caused by "ndtrait". (To use a plant-based example, maybe rooting depth drives niche differentiation, plant height drives competitive ability, and the two traits are positively associated.) Let's see if there's an association between the two traits:

```{r}
cor(ex_traits)
```

There is. What can we do about it? Let's include "domtrait" as a covariate. Including a suspected confounder as a covariate can help us in our quest for an unbiased estimate of the effect of "ndtrait" on co-occurrence probabilities. (We can never do perfect causal inference with observational data, but it's worth getting as close as we can. That's another topic.)

Let's try a new model using both "ndtrait" and "domtrait" with distance interactions. We'll start with rank=0. When the model's built, we'll run gofstats() and 'DHARMa' checks.

```{r}
nd_dom_0_mod <- buildcompnet(presabs=ex_presabs,
                        spvars_dist_int=ex_traits,
                        warmup=400,
                        iter=1200)

nd_dom_0_mod_gofstats <- gofstats(nd_dom_0_mod)
nd_dom_0_mod_gofstats

nd_dom_0_mod_ppred <- postpredsamp(nd_dom_0_mod)
fpr <- apply(nd_dom_0_mod_ppred, 1, mean)
nd_dom_0_mod_dharma <- createDHARMa(simulatedResponse = nd_dom_0_mod_ppred,
                                observedResponse = nd_dom_0_mod$d$both,
                                fittedPredictedResponse = fpr,
                                integerResponse = TRUE)
testDispersion(nd_dom_0_mod_dharma, plot=FALSE)
testQuantiles(nd_dom_0_mod_dharma, plot=FALSE)
testUniformity(nd_dom_0_mod_dharma, plot=FALSE)
testZeroInflation(nd_dom_0_mod_dharma, plot=FALSE)

```

We've got some issues with high-order non-independence and overdispersion, so let's try again with 'rank' = 1.

```{r}
nd_dom_1_mod <- buildcompnet(presabs=ex_presabs,
                        spvars_dist_int=ex_traits,
                        rank = 1,
                        warmup=500,
                        iter=1500)

nd_dom_1_mod_gofstats <- gofstats(nd_dom_1_mod)
nd_dom_1_mod_gofstats

nd_dom_1_mod_ppred <- compnet::postpredsamp(nd_dom_1_mod)
fpr <- apply(nd_dom_1_mod_ppred, 1, mean)
nd_dom_1_mod_dharma <- createDHARMa(simulatedResponse = nd_dom_1_mod_ppred,
                                observedResponse = nd_dom_1_mod$d$both,
                                fittedPredictedResponse = fpr,
                                integerResponse = TRUE)
testDispersion(nd_dom_1_mod_dharma, plot=FALSE)
testQuantiles(nd_dom_1_mod_dharma, plot=FALSE)
testUniformity(nd_dom_1_mod_dharma, plot=FALSE)
testZeroInflation(nd_dom_1_mod_dharma, plot=FALSE)

```

Much better. Let's have a quick look at our results and compare to the model with no covariate adjustment:

```{r}
summarize_compnet(nd_1_mod)
summarize_compnet(nd_dom_1_mod)
```

The coefficient of the "ndtrait" distance term is greater in the new model. This suggests our covariate adjustment strategy helped to "unmask" the true effect of "ndtrait" on co-occurrence probability. Let's see if the scatterplots look much different:

```{r fig.height=6, fig.width=6}
scatter_interaction(nd_1_mod, xvar="ndtrait", xlabel="ND Trait")
scatter_interaction(nd_dom_1_mod, xvar="ndtrait", xlabel="ND Trait")
```

The effect is noticeably, if modestly, stronger in the new model that incorporated covariate adjustment.

# Phylogenetic distance model (8-15 min.)

Sometimes we might not have trait data, or we might not be sure which traits make sense to use in our models. If we think phylogenetic distance serves as a reasonable proxy for resource use overlap, then we could use phylogenetic distance is a predictor in our 'compnet' model. Let's try this approach with the example data set.

First, we'll load the phylogenetic distance data and have a look.

```{r}
data("ex_phylo")
head(ex_phylo)
```

Rows represent species pairs. In addition to the phylodist column, there are two columns containing unique species names for each pair. These names must match the names in our presence-absence matrix.

Let's build the model now. Phylogenetic distance is a species-pair-level variable (not a species-level variable), so we'll tell buildcompnet() we want to use 'ex_phylo' with the 'pairvars' argument. We'll start with rank 0.

```{r}
phylo_0_mod <- buildcompnet(presabs=ex_presabs,
                            pairvars=ex_phylo,
                            warmup=400,
                            iter=1200)
```

Run our model checks:

```{r}
gofstats(phylo_0_mod)

phylo_0_mod_ppred <- postpredsamp(phylo_0_mod)
fpr <- apply(phylo_0_mod_ppred, 1, mean)
phylo_0_mod_dharma <- createDHARMa(simulatedResponse = phylo_0_mod_ppred,
                                observedResponse = phylo_0_mod$d$both,
                                fittedPredictedResponse = fpr,
                                integerResponse = TRUE)
testDispersion(phylo_0_mod_dharma, plot=FALSE)
testQuantiles(phylo_0_mod_dharma, plot=FALSE)
testUniformity(phylo_0_mod_dharma, plot=FALSE)
testZeroInflation(phylo_0_mod_dharma, plot=FALSE)
```

We've got problems with overdispersion and quantile deviations. Let's try again with 'rank' = 1.

```{r}
phylo_1_mod <- buildcompnet(presabs=ex_presabs,
                            pairvars=ex_phylo,
                            rank=1,
                            warmup=500,
                            iter=1500,
                            adapt_delta=0.9)
```

Run our model checks:

```{r}
gofstats(phylo_1_mod)

phylo_1_mod_ppred <- postpredsamp(phylo_1_mod)
fpr <- apply(phylo_1_mod_ppred, 1, mean)
phylo_1_mod_dharma <- createDHARMa(simulatedResponse = phylo_1_mod_ppred,
                                observedResponse = phylo_1_mod$d$both,
                                fittedPredictedResponse = fpr,
                                integerResponse = TRUE)
testDispersion(phylo_1_mod_dharma, plot=FALSE)
testQuantiles(phylo_1_mod_dharma, plot=FALSE)
testUniformity(phylo_1_mod_dharma, plot=FALSE)
testZeroInflation(phylo_1_mod_dharma, plot=FALSE)
```

Looks good! Let's visualize results:

```{r}
fixedeff_violins(phylo_1_mod)
```

```{r fig.height=6, fig.width=6}
scatter_pairvar(phylo_1_mod, xvar="phylodist", xlabel="Phylogenetic Distance")
```

Not much of an effect. We can regard this as a warning that phylogenetic distance may not always be an ideal proxy for resource use overlap.

# Alternative distributions

As alternatives to the binomial likelihood, 'compnet' models can also be built with [beta-binomial](https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html) or [zero-inflated binomial](https://r-nimble.org/nimbleExamples/zero_inflated_poisson.html) likelihoods by changing the 'family' argument in buildcompnet(). These options can sometimes help resolve the kinds of problems that 'DHARMa' checks reveal, like overdispersion or zero-inflation. Before turning to fancy solutions like these, it's often worthwhile to rethink our choices of predictor variables. However, that doesn't always work, so it's nice to have fancier model structures available in case we need them.
